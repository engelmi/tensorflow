\section{Technische Analyse von RSTensorFlow}
\label{sec:analyserstf}
Bei TensorFlow handelt es sich um ein umfangreiches und komplexes Projekt, weshalb eigene Anpassungen ein gutes Verständnis dieses Deep Learning Framworks erfordern. In diesem Kapitel wird zunächst eine technische Analyse des Quellcodes im Hinblick auf die von RSTensorFlow vorgenommenen Anpassungen in \ref{subsec:quellcodeanalyse} durchgeführt. Hier wird die Quellcode-Struktur von TensorFlow im Allgemeinen, sowie die Anpassungen von RSTensorFlow erläutert. Der Build-Prozess für die Android-Demo wird in \ref{subsec:buildprozess} untersucht. 

\subsection{Analyse des Quellcodes}
\label{subsec:quellcodeanalyse}
Die von TensorFlow bereits implementierten Demos für Android sind in Java geschrieben und verwenden das Android SDK. Das Deep Learning Framework TensorFlow hingegen ist mit C++ umgesetzt. Als Schnittstelle zwischen TensorFlow und Android wird das Android Native Development Kit (NDK) eingesetzt. Das NDK ermöglicht die Verwendung von C/C++ auf einer Android-Plattform und nutzt die Java Native Interface (JNI) API. \\
Das Framework TensorFlow wird für die Android-Demos in die Shared Object Datei \textit{libtensorflow\_inference.so} gepackt. In dieser .so-Datei befindet sich ebenfalls das \textit{TensorFlowInferenceInterface}, welches den Zugriff der Android-App auf TensorFlow durch das NDK realisiert. Somit können Deep Learning Anwendungen für Android auf diesen Kern aufsetzen und bequem Activities, welche auf das Inference Interface zugreifen, umgesetzt werden. 
\\
Für die Berechnungen der Matrixmultiplikation und der Convolution-Operation wird von TensorFlow die Eigen-Bibliothek \cite{todo-eigen} verwendet. Damit die substituierende Verwendung von RenderScript möglich ist, müssen die Aufrufe der Eigen-Bibliothek im Kernel von TensorFlow ersetzt werden. RenderScript ist jedoch für die direkte Verwendung in Java konzipiert, weshalb die Integration in den TensorFlow-Kernel komplex ist. Die Authoren von \cite{rstensorflow2017} haben zur Lösung des Problems für den Quellcode von RenderScript einen Wrapper in C++ umgesetzt, welcher das Skript aufruft. Die RenderScript-Dateien werden in separaten Shared Object Dateien gekapselt und stehen somit der Anwendung zur Verfügung. Für RSTensorFlow wurden so die Operationen matmul und conv2D in RenderScript umgesetzt. Damit TensorFlow statt der Eigen-Implementierung die RS-Variante nutzt, sind Anpassungen in den Quelldateien 
\begin{itemize}
	\item conv\_ops.cc und
	\item matmul\_op.cc
\end{itemize}
nötig. Statt des Aufrufs zur Berechnung durch die Eigen-Bibliothek wird die jeweilige Funktion des RenderScript-Wrappers aufgerufen. An den einzelnen Android-Activities sind aufgrund der Kapselung keinerlei weitere Änderungen nötig. Somit nutzt beispielsweise die TF Classify App, welche in \textit{ClassifierAcitivity.java} implementiert ist, automatisch die RenderScript-Unterstützung. 

\subsection{Der Build-Prozess}
\label{subsec:buildprozess}

+ tools - bazel, android sdk, ndk
+ fällt in bazel script auf dass .so Ordner nur eingebunden wird, aber nicht die RenderScript OPS kompiliert werden
	- auf <website> wird die modifizierte variante von libtensorflow.rs sowie die normale .so zur verfügung gestellt
	- für eigene kompilierung (z.B. bei anpassungen in tf oder auch bei den renderscript operationen) fehlt die librs.mScriptConv.so (kompilierung durch eigenständiges projekt, obwohl quelldateien in repo eingebunden)
+ nachdem technische aspekte geklärt sind, wird versucht die experimente aus \cite{rstensorflow2017} in \ref{subsec:rekonstruktion} zu rekonstruieren 
+ RSRuntime so's werden nur eingebunden, nicht kompiliert
- hier fehlt die librs.mScriptConv.so -> musste selbst kompiliert und eingebunden werden\\

+ das rstf projekt bietet auf der homepage die libtensorflowInference.so an - mit und ohne rs
- für anpassungen muss allerdings selbst die libtensorflowInference.so kompiliert werden
+ RSRuntime so's durch extra projekt kompilierbar
- librs.mScriptConv.so usw 
