\section{Einleitung}
\label{sec:einleitung}
In den vergangenen Jahren haben sich mobile Geräte, wie beispielsweise Smartphones, zu Assistenten des Alltags entwickelt. Auf diesen kleinen Helfern werden viele komplexe Anwendungen und Funktionen genutzt, welche verschiedenste Deep Learning Modelle verwenden. So werden beispielsweise Deep Recurrent Networks Neural Networks zur Spracherkennung \cite{bspSpracherkennung} genutzt. Zur Erkennung von Objekten werden Deep Convolutional Networks eingesetzt \cite{bspObjekterkennung}. Deep Learning Modelle führen viele sehr rechenintensive Berechnungen durch. Deshalb wird bevorzugt eine Art Client-Server-Anwendung umgesetzt, welche das Deep Learning Modell auf einem separaten Server ausführt. Die mobilen Clients schicken über eine entsprechende App die benötigten Eingangsdaten für das Netzwerk an den Server und dieser schickt das Ergebnis des Deep Learning Netzwerks zurück an den Client. Dies ist sowohl zeit- als auch kostenintensiv. Um Deep Learning Netzwerke direkt auf dem Mobilgerät zu verwenden, bieten Frameworks wie TensorFlow (\url{https://www.tensorflow.org/}) eine eigene Variante der Software an. Jedoch nutzen diese nicht alle Rechenressourcen des Endgeräts, sondern lediglich die CPU. Für größere Applikationen ist dies oft nicht ausreichend, um in angemessener Zeit ein adäquates Ergebnis zu erhalten. Projekte wie RSTensorFlow \cite{rstensorflow2017} versuchen daher eine Unterstützung der GPU in das bestehende OpenSource-Framework TensorFlow zu integrieren und den Erfolg anhand geeigneter Metriken zu bewerten. \\
Die Veröffentlichung zum Projekt \textit{RSTensorFlow} \cite{rstensorflow2017} dient als zentrale Arbeit dieses Papers und stellt den Ausgangspunkt dar. Die in \cite{rstensorflow2017} beschriebenen Experimente werden in diesem Paper nachgestellt und für andere Geräte, welche nicht direkt von Google hergestellt wurden, durchgeführt. Über die angepasste \textit{TF Classify} App werden die Ausführungszeiten gemessen. Ebenso wird mit Hilfe der \textit{Trepn Profiler} App die Auslastung der CPU und GPU überprüft. Diese Anwendung dient ebenfalls dem Aufzeichnen weiterer Metriken, wie beispielsweise der Auslastung des Speichers. Diese wurde bereits in \cite{rstensorflow2017} als ein mögliches Bottleneck hinsichtlich der Performance vermutet. Für eine Optimierung der Conv2D-Operation wird das sogenannte Unfolding näher betrachtet. In \cite{conv2d-optimizing-unfolding} sowie in \cite{Rajbhandari:2017:OCM:3037697.3037745} werden mit dieser Technik Convolutional Networks optimiert. Hierfür wägen beide Arbeiten das Potential des Unfoldings ab und erläutern die Funktionsweise. 
\\ 
